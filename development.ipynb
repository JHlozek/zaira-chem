{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signaturizer import Signaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = Signaturizer('GLOBAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sign.predict([\"CCC\", \"CCOCC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0252775 ,  0.09000354,  0.0950816 , ...,  0.10229832,\n",
       "         0.05383358,  0.07792108],\n",
       "       [-0.00669635,  0.09058492,  0.09547642, ...,  0.11125947,\n",
       "         0.05668775,  0.09412433]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mordred\n",
      "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six==1.* in /Users/mduran/opt/anaconda3/envs/sign/lib/python3.7/site-packages (from mordred) (1.15.0)\n",
      "Requirement already satisfied: numpy==1.* in /Users/mduran/opt/anaconda3/envs/sign/lib/python3.7/site-packages (from mordred) (1.19.5)\n",
      "Collecting networkx==2.*\n",
      "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /Users/mduran/opt/anaconda3/envs/sign/lib/python3.7/site-packages (from networkx==2.*->mordred) (4.4.2)\n",
      "Building wheels for collected packages: mordred\n",
      "  Building wheel for mordred (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176721 sha256=bd4a46bbbe9f93b6aa7c56a04adac4414890fea2431192fc1ed286f5f7e08489\n",
      "  Stored in directory: /Users/mduran/Library/Caches/pip/wheels/02/c0/2e/e7e3d63b431777712ebc128bc4deb9ac5cb19afc7c1ea341ec\n",
      "Successfully built mordred\n",
      "Installing collected packages: networkx, mordred\n",
      "Successfully installed mordred-1.2.0 networkx-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mordred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:24:26] {908} INFO - Evaluation method: cv\n",
      "[flaml.automl: 06-29 15:24:26] {617} INFO - Using RepeatedKFold\n",
      "[flaml.automl: 06-29 15:24:26] {929} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 06-29 15:24:26] {948} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
      "[flaml.automl: 06-29 15:24:26] {1012} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:26] {1159} INFO -  at 0.2s,\tbest lgbm's error=0.6257,\tbest lgbm's error=0.6257\n",
      "[flaml.automl: 06-29 15:24:26] {1012} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:26] {1159} INFO -  at 0.2s,\tbest lgbm's error=0.6257,\tbest lgbm's error=0.6257\n",
      "[flaml.automl: 06-29 15:24:26] {1012} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:26] {1159} INFO -  at 0.3s,\tbest lgbm's error=0.3431,\tbest lgbm's error=0.3431\n",
      "[flaml.automl: 06-29 15:24:26] {1012} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:26] {1159} INFO -  at 0.3s,\tbest lgbm's error=0.2876,\tbest lgbm's error=0.2876\n",
      "[flaml.automl: 06-29 15:24:26] {1012} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.4s,\tbest lgbm's error=0.2876,\tbest lgbm's error=0.2876\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.4s,\tbest lgbm's error=0.2425,\tbest lgbm's error=0.2425\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.5s,\tbest lgbm's error=0.2354,\tbest lgbm's error=0.2354\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.5s,\tbest lgbm's error=0.2180,\tbest lgbm's error=0.2180\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.6s,\tbest lgbm's error=0.2152,\tbest lgbm's error=0.2152\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.7s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.7s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.8s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.8s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.9s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 0.9s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.0s,\tbest xgboost's error=3.1930,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.0s,\tbest lgbm's error=0.1846,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.1s,\tbest xgboost's error=3.1930,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.1s,\tbest xgboost's error=0.8907,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.2s,\tbest xgboost's error=0.3203,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.2s,\tbest xgboost's error=0.3203,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:27] {1159} INFO -  at 1.3s,\tbest xgboost's error=0.2798,\tbest lgbm's error=0.1846\n",
      "[flaml.automl: 06-29 15:24:27] {1012} INFO - iteration 22, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.4s,\tbest extra_tree's error=0.1506,\tbest extra_tree's error=0.1506\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.5s,\tbest extra_tree's error=0.1430,\tbest extra_tree's error=0.1430\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.5s,\tbest extra_tree's error=0.1430,\tbest extra_tree's error=0.1430\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.6s,\tbest extra_tree's error=0.1324,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.7s,\tbest extra_tree's error=0.1324,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.8s,\tbest extra_tree's error=0.1324,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.8s,\tbest extra_tree's error=0.1324,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 1.9s,\tbest lgbm's error=0.1770,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 2.0s,\tbest xgboost's error=0.2798,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 2.1s,\tbest xgboost's error=0.2798,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 2.1s,\tbest extra_tree's error=0.1324,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 2.2s,\tbest rf's error=0.1952,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 06-29 15:24:28] {1159} INFO -  at 2.3s,\tbest rf's error=0.1877,\tbest extra_tree's error=0.1324\n",
      "[flaml.automl: 06-29 15:24:28] {1012} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:29] {1159} INFO -  at 2.4s,\tbest extra_tree's error=0.1277,\tbest extra_tree's error=0.1277\n",
      "[flaml.automl: 06-29 15:24:29] {1012} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:29] {1159} INFO -  at 2.6s,\tbest extra_tree's error=0.1224,\tbest extra_tree's error=0.1224\n",
      "[flaml.automl: 06-29 15:24:29] {1012} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:29] {1159} INFO -  at 2.6s,\tbest extra_tree's error=0.1224,\tbest extra_tree's error=0.1224\n",
      "[flaml.automl: 06-29 15:24:29] {1012} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:29] {1159} INFO -  at 2.7s,\tbest extra_tree's error=0.1224,\tbest extra_tree's error=0.1224\n",
      "[flaml.automl: 06-29 15:24:29] {1012} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:29] {1159} INFO -  at 3.0s,\tbest extra_tree's error=0.1122,\tbest extra_tree's error=0.1122\n",
      "[flaml.automl: 06-29 15:24:29] {1012} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:30] {1159} INFO -  at 3.7s,\tbest extra_tree's error=0.1002,\tbest extra_tree's error=0.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:24:30] {1012} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:30] {1159} INFO -  at 3.9s,\tbest extra_tree's error=0.1002,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:30] {1012} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 06-29 15:24:30] {1159} INFO -  at 4.0s,\tbest lgbm's error=0.1770,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:30] {1012} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 6.8s,\tbest extra_tree's error=0.1002,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 6.9s,\tbest extra_tree's error=0.1002,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 6.9s,\tbest xgboost's error=0.2798,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 7.0s,\tbest rf's error=0.1617,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 7.1s,\tbest xgboost's error=0.2556,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 7.2s,\tbest rf's error=0.1617,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 06-29 15:24:33] {1159} INFO -  at 7.3s,\tbest rf's error=0.1617,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:33] {1012} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:24:36] {1159} INFO -  at 9.8s,\tbest extra_tree's error=0.1002,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:36] {1012} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 06-29 15:24:36] {1159} INFO -  at 9.8s,\tbest rf's error=0.1617,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:36] {1012} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 06-29 15:24:36] {1159} INFO -  at 9.9s,\tbest rf's error=0.1617,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:36] {1012} INFO - iteration 53, current learner catboost\n",
      "[flaml.automl: 06-29 15:24:37] {1159} INFO -  at 10.7s,\tbest catboost's error=0.9159,\tbest extra_tree's error=0.1002\n",
      "[flaml.automl: 06-29 15:24:37] {1205} INFO - selected model: ExtraTreesRegressor(max_features=0.3538690303233088, n_estimators=111,\n",
      "                    n_jobs=-1)\n",
      "[flaml.automl: 06-29 15:24:37] {963} INFO - fit succeeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.         21.6        34.7        33.4        36.2        28.7\n",
      " 22.9        27.1        16.5        18.9        15.         18.9\n",
      " 21.7        20.4        18.2        19.9        23.1        17.5\n",
      " 20.2        18.2        13.6        19.6        15.2        14.5\n",
      " 15.6        13.9        16.6        14.8        18.4        21.\n",
      " 12.7        14.5        13.2        13.1        13.5        18.9\n",
      " 20.         21.00540541 24.7        30.8        34.9        26.6\n",
      " 25.3        24.7        21.2        19.3        20.         16.6\n",
      " 14.4        19.4        19.7        20.5        25.         23.4\n",
      " 18.9        35.4        24.7        31.6        23.3        19.6\n",
      " 18.7        16.         22.2        25.         33.         23.5\n",
      " 19.4        22.         17.4        20.9        24.2        21.7\n",
      " 22.8        23.4        24.1        21.4        20.         20.8\n",
      " 21.2        20.3        28.         23.9        24.8        22.9\n",
      " 23.89369369 26.6        22.50630631 22.19459459 23.6        28.7\n",
      " 22.6        22.         22.9        25.         20.6        28.4\n",
      " 21.4        38.7        43.8        33.2        27.5        26.5\n",
      " 18.6        19.3        20.09864865 19.50405405 19.5        20.39594595\n",
      " 19.80135135 19.4        21.7        22.8        18.8045045  18.70540541\n",
      " 18.50720721 18.30900901 21.18288288 19.2009009  20.39009009 19.3\n",
      " 22.         20.3        20.5        17.3        18.8        21.4\n",
      " 15.7        16.2        18.         14.3        19.2        19.6\n",
      " 23.         18.4        15.6        18.1        17.4        17.1\n",
      " 13.3        17.8        14.         14.4        13.4        15.6\n",
      " 11.8        13.8        15.6        14.6        17.8        15.4\n",
      " 21.5        19.6        15.3        19.4        17.         15.6\n",
      " 13.1        41.3        24.3        23.3        27.         50.\n",
      " 50.         50.         22.7        25.         50.         23.8\n",
      " 23.8        22.3        17.4        19.1        23.1        23.5954955\n",
      " 22.6045045  29.4        23.2        24.6        29.9        37.2\n",
      " 39.8        36.2        37.9        32.5        26.4        29.6\n",
      " 50.         32.         29.8        34.9        37.         30.5\n",
      " 36.4        31.1        29.1        50.         33.3        30.3\n",
      " 34.6        34.9        32.9        24.1        42.3        48.5\n",
      " 50.         22.6        24.4        22.5        24.4        20.\n",
      " 21.7        19.3        22.4        28.1        23.7        25.\n",
      " 23.3        28.7        21.5        23.         26.7        21.7\n",
      " 27.5        30.1        44.8        50.         37.6        31.6\n",
      " 46.7        31.5        24.3        31.7        41.7        48.3\n",
      " 29.         24.         25.1        31.5        23.7        23.3\n",
      " 22.         20.1        22.2        23.7        17.6        18.5\n",
      " 24.3        20.5        24.5        26.2        24.4        24.8\n",
      " 29.6        42.8        21.9        20.9        44.         50.\n",
      " 36.         30.1        33.8        43.1        48.8        31.\n",
      " 36.5        22.8        30.7        50.         43.5        20.7\n",
      " 21.1        25.2        24.4        35.2        32.4        32.\n",
      " 33.2        33.1        29.1        35.1        45.4        35.4\n",
      " 46.         50.         32.2        22.         20.1        23.2\n",
      " 22.3        24.8        28.5        37.3        27.9        23.9\n",
      " 21.7        28.6        27.1        20.3        22.5        29.\n",
      " 24.8        22.         26.4        33.1        36.1        28.4\n",
      " 33.4        28.2        22.8        20.3        16.1        22.1\n",
      " 19.38558559 21.6        23.8        16.21441441 17.8        19.8\n",
      " 23.1        21.         23.8        23.1        20.4        18.5\n",
      " 25.         24.6        23.         22.2        19.3        22.6\n",
      " 19.8        17.1        19.4        22.2        20.7        21.1\n",
      " 19.5        18.5        20.6        19.         18.7        32.7\n",
      " 16.5        23.9        31.2        17.5        17.2        23.1\n",
      " 24.5        26.6        22.9        24.1        18.6        30.1\n",
      " 18.2        20.6        17.81756757 21.68243243 22.67342342 22.6\n",
      " 25.         19.9        20.8        16.82657658 21.9        27.5\n",
      " 21.9        23.1        50.         50.         50.         50.\n",
      " 50.         13.8        13.8        15.         13.9        13.3\n",
      " 13.1        10.2        10.4        10.9        11.3        12.3\n",
      "  8.8         7.2        10.5         7.4        10.2        11.5\n",
      " 15.1        23.2         9.7        13.8        12.7        13.1\n",
      " 12.5         8.5         5.          6.3         5.6         7.2\n",
      " 12.1         8.3         8.5         5.         11.9        27.9\n",
      " 17.2        27.5        15.         17.2        17.9        16.3\n",
      "  7.          7.2         7.5        10.4         8.8         8.4\n",
      " 16.7        14.2        20.8        13.4        11.7         8.3\n",
      " 10.2        10.9        11.          9.5        14.5        14.1\n",
      " 16.1        14.3        11.7        13.4         9.6         8.7\n",
      "  8.4        12.8        10.5        17.1        18.4        15.4\n",
      " 10.8        11.8        14.9        12.6        14.1        13.\n",
      " 13.4        15.2        16.1027027  17.8        14.9        14.1\n",
      " 12.7        13.5        14.9        20.         16.4        17.7\n",
      " 19.5        20.2        21.4        19.9        19.         19.1\n",
      " 19.1        20.1        19.9        19.6        23.2        29.8\n",
      " 13.8        13.3        16.6972973  12.         14.6        21.4\n",
      " 23.         23.7        25.         21.8        20.6        21.2\n",
      " 19.1        20.6        15.2         7.          8.1        13.6\n",
      " 20.1        21.8        24.5        23.1        19.7        18.3\n",
      " 21.2        17.5        16.8        22.4        20.6        23.9\n",
      " 22.         11.9       ]\n",
      "<flaml.model.ExtraTreeEstimator object at 0x7fe13be52370>\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_boston\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression'\n",
    "}\n",
    "X_train, y_train = load_boston(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n",
    "# Predict\n",
    "print(automl.predict(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:51:22] {908} INFO - Evaluation method: cv\n",
      "[flaml.automl: 06-29 15:51:22] {607} INFO - Using StratifiedKFold\n",
      "[flaml.automl: 06-29 15:51:22] {929} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 06-29 15:51:22] {948} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.1s,\tbest lgbm's error=0.0733,\tbest lgbm's error=0.0733\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.1s,\tbest lgbm's error=0.0733,\tbest lgbm's error=0.0733\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.1s,\tbest lgbm's error=0.0667,\tbest lgbm's error=0.0667\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.2s,\tbest lgbm's error=0.0467,\tbest lgbm's error=0.0467\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.2s,\tbest lgbm's error=0.0467,\tbest lgbm's error=0.0467\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.3s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.3s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.4s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.4s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.4s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.5s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.6s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:22] {1159} INFO -  at 0.6s,\tbest extra_tree's error=0.0667,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:22] {1012} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 0.7s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 0.7s,\tbest extra_tree's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 15, current learner rf\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 0.8s,\tbest rf's error=0.0533,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 0.9s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 0.9s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.0s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 19, current learner rf\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.1s,\tbest rf's error=0.0533,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.2s,\tbest rf's error=0.0533,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 21, current learner rf\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.2s,\tbest rf's error=0.0467,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.2s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.3s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.4s,\tbest extra_tree's error=0.0467,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.5s,\tbest extra_tree's error=0.0467,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.5s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.6s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:23] {1159} INFO -  at 1.7s,\tbest extra_tree's error=0.0467,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:23] {1012} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 1.8s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 1.8s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 1.8s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 1.9s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.0s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.1s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.2s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.2s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.3s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.4s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.5s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.6s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:24] {1159} INFO -  at 2.7s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:51:24] {1012} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 2.7s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 2.8s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 2.9s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.0s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.0s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.1s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.1s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.2s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.3s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.4s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.5s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.5s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.5s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.6s,\tbest xgboost's error=0.0600,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:25] {1159} INFO -  at 3.6s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:25] {1012} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 3.7s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 3.8s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 3.8s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 3.9s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 3.9s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.0s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.0s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 64, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.1s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.2s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.3s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.3s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.4s,\tbest lgbm's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.4s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.5s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.6s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:26] {1159} INFO -  at 4.7s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:26] {1012} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.7s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.8s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0400\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.8s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.8s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.9s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 4.9s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.0s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.1s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.1s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.2s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.3s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.4s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 85, current learner rf\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.4s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.5s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 87, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.5s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.6s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:27] {1159} INFO -  at 5.7s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:27] {1012} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 5.8s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 5.8s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 93, current learner rf\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.0s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.1s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.2s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.2s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.3s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 98, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.3s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.4s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.4s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.5s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.5s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:28] {1159} INFO -  at 6.7s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:28] {1012} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 6.8s,\tbest extra_tree's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 6.9s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.0s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.2s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.2s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.3s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.4s,\tbest xgboost's error=0.0533,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.5s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:29] {1159} INFO -  at 7.5s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:29] {1012} INFO - iteration 115, current learner catboost\n",
      "[flaml.automl: 06-29 15:51:30] {1159} INFO -  at 8.0s,\tbest catboost's error=0.0467,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:30] {1012} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:30] {1159} INFO -  at 8.1s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:30] {1012} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:30] {1159} INFO -  at 8.1s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:30] {1012} INFO - iteration 118, current learner catboost\n",
      "[flaml.automl: 06-29 15:51:30] {1159} INFO -  at 8.6s,\tbest catboost's error=0.0467,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:30] {1012} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:30] {1159} INFO -  at 8.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:30] {1012} INFO - iteration 120, current learner catboost\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 8.9s,\tbest catboost's error=0.0467,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 121, current learner catboost\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.2s,\tbest catboost's error=0.0467,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.3s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 123, current learner catboost\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.5s,\tbest catboost's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.5s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.6s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:31] {1159} INFO -  at 9.7s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:31] {1012} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 06-29 15:51:32] {1159} INFO -  at 9.7s,\tbest lgbm's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:32] {1012} INFO - iteration 129, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 06-29 15:51:32] {1159} INFO -  at 9.8s,\tbest extra_tree's error=0.0333,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:32] {1012} INFO - iteration 130, current learner rf\n",
      "[flaml.automl: 06-29 15:51:32] {1159} INFO -  at 10.0s,\tbest rf's error=0.0400,\tbest lgbm's error=0.0333\n",
      "[flaml.automl: 06-29 15:51:32] {1012} INFO - iteration 131, current learner lrl1\n",
      "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
      "/Users/mduran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/mduran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/mduran/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[flaml.automl: 06-29 15:51:32] {1159} INFO -  at 10.0s,\tbest lrl1's error=0.0222,\tbest lrl1's error=0.0222\n",
      "[flaml.automl: 06-29 15:51:32] {1205} INFO - selected model: LogisticRegression(n_jobs=-1, penalty='l1', solver='saga')\n",
      "[flaml.automl: 06-29 15:51:32] {963} INFO - fit succeeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.87442316e-01 1.25576488e-02 3.54509120e-08]\n",
      " [9.64515324e-01 3.54843750e-02 3.00974056e-07]\n",
      " [9.80326128e-01 1.96737407e-02 1.31065905e-07]\n",
      " [9.58395788e-01 4.16035662e-02 6.45934734e-07]\n",
      " [9.89363919e-01 1.06360502e-02 3.03584713e-08]\n",
      " [9.88595379e-01 1.14045775e-02 4.30195247e-08]\n",
      " [9.82242109e-01 1.77577096e-02 1.81078989e-07]\n",
      " [9.79432777e-01 2.05671186e-02 1.03967552e-07]\n",
      " [9.49983343e-01 5.00155277e-02 1.12933684e-06]\n",
      " [9.61786896e-01 3.82128372e-02 2.66519185e-07]\n",
      " [9.89944045e-01 1.00559388e-02 1.65505820e-08]\n",
      " [9.71523537e-01 2.84762025e-02 2.60610656e-07]\n",
      " [9.63177929e-01 3.68217998e-02 2.71474776e-07]\n",
      " [9.80459426e-01 1.95404248e-02 1.49124082e-07]\n",
      " [9.97818899e-01 2.18110021e-03 5.30130199e-10]\n",
      " [9.97753858e-01 2.24614108e-03 1.41150604e-09]\n",
      " [9.96097931e-01 3.90206365e-03 5.12956740e-09]\n",
      " [9.87524524e-01 1.24754280e-02 4.77870062e-08]\n",
      " [9.87270940e-01 1.27290344e-02 2.51611449e-08]\n",
      " [9.90992891e-01 9.00708026e-03 2.82895572e-08]\n",
      " [9.69236279e-01 3.07635848e-02 1.36141288e-07]\n",
      " [9.89095182e-01 1.09047637e-02 5.42102099e-08]\n",
      " [9.95872508e-01 4.12748434e-03 7.94431398e-09]\n",
      " [9.59888568e-01 4.01105831e-02 8.48611245e-07]\n",
      " [9.38180546e-01 6.18182070e-02 1.24731605e-06]\n",
      " [9.42362636e-01 5.76366618e-02 7.02138623e-07]\n",
      " [9.73572186e-01 2.64274939e-02 3.20111249e-07]\n",
      " [9.84117079e-01 1.58828715e-02 4.94800626e-08]\n",
      " [9.85178740e-01 1.48212189e-02 4.13830557e-08]\n",
      " [9.56832215e-01 4.31671514e-02 6.34024718e-07]\n",
      " [9.49334153e-01 5.06651110e-02 7.36005996e-07]\n",
      " [9.82075704e-01 1.79242097e-02 8.62111639e-08]\n",
      " [9.95123297e-01 4.87669831e-03 4.44393092e-09]\n",
      " [9.97240724e-01 2.75927443e-03 1.36971618e-09]\n",
      " [9.62030545e-01 3.79690956e-02 3.59322769e-07]\n",
      " [9.86262775e-01 1.37371821e-02 4.28594751e-08]\n",
      " [9.91521743e-01 8.47824705e-03 9.50393995e-09]\n",
      " [9.88952317e-01 1.10476555e-02 2.74095696e-08]\n",
      " [9.68135247e-01 3.18642795e-02 4.73898486e-07]\n",
      " [9.80062395e-01 1.99375193e-02 8.54530603e-08]\n",
      " [9.90143526e-01 9.85643951e-03 3.42130894e-08]\n",
      " [8.86342747e-01 1.13651538e-01 5.71525875e-06]\n",
      " [9.78403500e-01 2.15962644e-02 2.36039680e-07]\n",
      " [9.78534526e-01 2.14650639e-02 4.10355548e-07]\n",
      " [9.74099892e-01 2.58997914e-02 3.16718689e-07]\n",
      " [9.63646675e-01 3.63528314e-02 4.93438806e-07]\n",
      " [9.88156053e-01 1.18439112e-02 3.56822287e-08]\n",
      " [9.73579518e-01 2.64202120e-02 2.70182337e-07]\n",
      " [9.89623184e-01 1.03767955e-02 2.01428897e-08]\n",
      " [9.80801446e-01 1.91984671e-02 8.69817885e-08]\n",
      " [1.09143901e-02 9.46139794e-01 4.29458159e-02]\n",
      " [1.47830309e-02 8.97397119e-01 8.78198502e-02]\n",
      " [4.67283569e-03 8.70395439e-01 1.24931726e-01]\n",
      " [6.20066904e-03 7.94179516e-01 1.99619815e-01]\n",
      " [4.84177064e-03 8.29327216e-01 1.65831013e-01]\n",
      " [4.44124170e-03 7.58557494e-01 2.37001265e-01]\n",
      " [9.22757547e-03 8.07200869e-01 1.83571556e-01]\n",
      " [4.70134129e-02 9.19251400e-01 3.37351875e-02]\n",
      " [6.68534275e-03 9.20636772e-01 7.26778855e-02]\n",
      " [1.66110793e-02 7.98088908e-01 1.85300013e-01]\n",
      " [1.24490723e-02 8.99740164e-01 8.78107637e-02]\n",
      " [1.82839723e-02 8.62789913e-01 1.18926114e-01]\n",
      " [6.93748198e-03 9.44486391e-01 4.85761272e-02]\n",
      " [3.59929781e-03 7.55905637e-01 2.40495065e-01]\n",
      " [7.10049142e-02 9.02394630e-01 2.66004557e-02]\n",
      " [1.82377243e-02 9.44546268e-01 3.72160080e-02]\n",
      " [5.68677821e-03 6.63508213e-01 3.30805009e-01]\n",
      " [1.35116001e-02 9.45718675e-01 4.07697254e-02]\n",
      " [1.28111212e-03 6.10813088e-01 3.87905800e-01]\n",
      " [1.43718884e-02 9.25158417e-01 6.04696950e-02]\n",
      " [2.85228710e-03 4.47152507e-01 5.49995206e-01]\n",
      " [2.39910055e-02 9.35559589e-01 4.04494052e-02]\n",
      " [6.77868067e-04 5.06398153e-01 4.92923979e-01]\n",
      " [3.19209533e-03 8.29578416e-01 1.67229488e-01]\n",
      " [1.43837360e-02 9.38853773e-01 4.67624912e-02]\n",
      " [1.43225668e-02 9.34993487e-01 5.06839460e-02]\n",
      " [3.21578991e-03 8.65143792e-01 1.31640418e-01]\n",
      " [2.04445970e-03 6.40501600e-01 3.57453941e-01]\n",
      " [6.08984536e-03 7.64212780e-01 2.29697375e-01]\n",
      " [5.35597052e-02 9.35031044e-01 1.14092504e-02]\n",
      " [1.48766537e-02 9.21458083e-01 6.36652630e-02]\n",
      " [1.98174317e-02 9.43277899e-01 3.69046691e-02]\n",
      " [2.31837570e-02 9.33096946e-01 4.37192969e-02]\n",
      " [2.87835843e-04 2.70379507e-01 7.29332657e-01]\n",
      " [4.72724267e-03 5.87693325e-01 4.07579433e-01]\n",
      " [1.79907936e-02 8.26039350e-01 1.55969856e-01]\n",
      " [7.67536240e-03 8.87694805e-01 1.04629833e-01]\n",
      " [2.85727220e-03 8.36081601e-01 1.61061126e-01]\n",
      " [2.22521054e-02 8.93430718e-01 8.43171762e-02]\n",
      " [9.73117494e-03 8.35868537e-01 1.54400288e-01]\n",
      " [3.57951786e-03 7.46450248e-01 2.49970234e-01]\n",
      " [6.25775536e-03 8.21575705e-01 1.72166540e-01]\n",
      " [1.42935339e-02 9.20244780e-01 6.54616859e-02]\n",
      " [4.00479747e-02 9.26329235e-01 3.36227904e-02]\n",
      " [8.66256613e-03 8.29592013e-01 1.61745421e-01]\n",
      " [1.77838603e-02 9.12200910e-01 7.00152300e-02]\n",
      " [1.41285455e-02 8.79076354e-01 1.06795101e-01]\n",
      " [1.32683443e-02 9.22796276e-01 6.39353793e-02]\n",
      " [1.29315823e-01 8.58731414e-01 1.19527632e-02]\n",
      " [1.53107855e-02 8.88000586e-01 9.66886283e-02]\n",
      " [3.29743934e-06 9.08953188e-03 9.90907171e-01]\n",
      " [9.82459988e-05 9.63916705e-02 9.03510083e-01]\n",
      " [2.85437817e-05 8.71314693e-02 9.12839987e-01]\n",
      " [4.92708303e-05 1.07429707e-01 8.92521022e-01]\n",
      " [1.17478782e-05 3.28969315e-02 9.67091321e-01]\n",
      " [1.93037058e-06 3.32863861e-02 9.66711684e-01]\n",
      " [3.51121134e-04 1.37055812e-01 8.62593067e-01]\n",
      " [8.57842046e-06 9.01565219e-02 9.09834900e-01]\n",
      " [9.43318295e-06 6.91219679e-02 9.30868599e-01]\n",
      " [3.15819375e-05 4.70735103e-02 9.52894908e-01]\n",
      " [1.21698634e-03 3.49850704e-01 6.48932309e-01]\n",
      " [1.04133774e-04 1.44931189e-01 8.54964677e-01]\n",
      " [1.25467704e-04 1.43044590e-01 8.56829942e-01]\n",
      " [5.23423162e-05 5.99391131e-02 9.40008545e-01]\n",
      " [3.38985761e-05 2.63455452e-02 9.73620556e-01]\n",
      " [1.95268029e-04 9.74712784e-02 9.02333454e-01]\n",
      " [1.58413395e-04 2.02648210e-01 7.97193377e-01]\n",
      " [1.66185884e-05 7.30780543e-02 9.26905327e-01]\n",
      " [6.52295427e-08 5.37436170e-03 9.94625573e-01]\n",
      " [1.18671157e-04 2.32575849e-01 7.67305480e-01]\n",
      " [6.30696708e-05 7.91092516e-02 9.20827679e-01]\n",
      " [2.02693458e-04 1.00450084e-01 8.99347222e-01]\n",
      " [9.18614021e-07 3.01745741e-02 9.69824507e-01]\n",
      " [7.30091156e-04 3.58549798e-01 6.40720111e-01]\n",
      " [1.05569852e-04 1.17093781e-01 8.82800649e-01]\n",
      " [8.57218247e-05 2.27195784e-01 7.72718495e-01]\n",
      " [1.31954564e-03 4.18174397e-01 5.80506057e-01]\n",
      " [1.35419242e-03 3.89183547e-01 6.09462261e-01]\n",
      " [1.83727652e-05 4.64530483e-02 9.53528579e-01]\n",
      " [1.72471935e-04 4.02511828e-01 5.97315700e-01]\n",
      " [1.54472648e-05 1.11170743e-01 8.88813809e-01]\n",
      " [1.65544892e-04 3.07980074e-01 6.91854381e-01]\n",
      " [1.37996785e-05 3.46592871e-02 9.65326913e-01]\n",
      " [6.96155449e-04 4.90146802e-01 5.09157043e-01]\n",
      " [3.58989772e-05 1.55954077e-01 8.44010024e-01]\n",
      " [1.78114297e-05 7.61079188e-02 9.23874270e-01]\n",
      " [5.18263457e-05 3.99928447e-02 9.59955329e-01]\n",
      " [1.85753298e-04 2.00870014e-01 7.98944233e-01]\n",
      " [1.82207956e-03 4.12625227e-01 5.85552694e-01]\n",
      " [3.33204951e-04 2.30064024e-01 7.69602771e-01]\n",
      " [3.90519069e-05 4.83291777e-02 9.51631770e-01]\n",
      " [8.69024222e-04 2.63384272e-01 7.35746703e-01]\n",
      " [9.82459988e-05 9.63916705e-02 9.03510083e-01]\n",
      " [1.85552094e-05 4.12276095e-02 9.58753835e-01]\n",
      " [3.48663479e-05 3.76568709e-02 9.62308263e-01]\n",
      " [2.80492981e-04 1.44898403e-01 8.54821104e-01]\n",
      " [1.98179330e-04 1.88849667e-01 8.10952154e-01]\n",
      " [4.15424852e-04 2.33272763e-01 7.66311812e-01]\n",
      " [1.60679020e-04 7.50805056e-02 9.24758815e-01]\n",
      " [4.05581867e-04 2.13132476e-01 7.86461943e-01]]\n",
      "<flaml.model.LRL1Classifier object at 0x7fe12c7278b0>\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_iris\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'accuracy',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"/tmp/iris.log\",\n",
    "}\n",
    "X_train, y_train = load_iris(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n",
    "# Predict\n",
    "print(automl.predict_proba(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033333333333333326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [16:13:32] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mordred import Calculator, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = Chem.MolFromSmiles('c1ccccc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>LogEE_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.242641</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.687624</td>\n",
       "      <td>...</td>\n",
       "      <td>7.627057</td>\n",
       "      <td>30.941317</td>\n",
       "      <td>78.04695</td>\n",
       "      <td>6.503913</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1613 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABC  ABCGG  nAcid  nBase  SpAbs_A  SpMax_A  SpDiam_A  SpAD_A  \\\n",
       "0  4.242641    4.0      0      0      8.0      2.0       4.0     8.0   \n",
       "\n",
       "    SpMAD_A   LogEE_A  ...     SRW10     TSRW10        MW       AMW  WPath  \\\n",
       "0  1.333333  2.687624  ...  7.627057  30.941317  78.04695  6.503913     27   \n",
       "\n",
       "   WPol  Zagreb1  Zagreb2  mZagreb1  mZagreb2  \n",
       "0     3     24.0     24.0       1.5       1.5  \n",
       "\n",
       "[1 rows x 1613 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc.pandas([mol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
